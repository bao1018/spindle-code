# -*- mode: python -*-

import os

DEBUG = True
TEMPLATE_DEBUG = DEBUG

ADMINS = (
    ('Your Name', 'Your Email'),
)

MANAGERS = ADMINS

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.', # Add 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'.
        'NAME': '',                      # Or path to database file if using sqlite3.
        'USER': '',                      # Not used with sqlite3.
        'PASSWORD': '',                  # Not used with sqlite3.
        'HOST': '',                      # Set to empty string for localhost. Not used with sqlite3.
        'PORT': '',                      # Set to empty string for default. Not used with sqlite3.
    }
}

# Make this unique, and don't share it with anybody.
SECRET_KEY = ''

EMAIL_HOST = ''
EMAIL_IMAP = ''
EMAIL_HOST_USER = ''
EMAIL_HOST_PASSWORD = ''
EMAIL_PORT = 587
EMAIL_USE_TLS = True
EMAIL_SUBJECT_PREFIX = ''

#----------------------------------------
# Spindle settings
#----------------------------------------

# URL of an RSS feed to scrape audio and video from
SPINDLE_SCRAPE_RSS_URL = ''

# New items added from RSS will be added to the transcription queue
# using the transcription engine defined below.  To disable this
# behavior, set explicitly to None:
SPINDLE_DEFAULT_TRANSCRIPTION_ENGINE = 'spindle.transcribe.sphinx'
 
# The absolute path to the CMU Sphinx installation, so that
# SPINDLE_SPHINX_DIRECTORY/bin/Transcriber.jar is the appropriate .jar
# file
SPINDLE_SPHINX_DIRECTORY = ''

# A directory where Sphinx output and logging information will be saved
# If this is blank, will use a default temporary file directory
SPINDLE_SPHINX_OUTPUT_DIRECTORY = ''

# A public directory for published captions and transcripts
SPINDLE_PUBLIC_DIRECTORY = ''

# URL for published items
SPINDLE_PUBLIC_URL = ''

# Filename for the RSS feed of exported plain text and keywords.  The
# full URL will be SPINDLE_PUBLIC_URL/SPINDLE_PUBLISH_RSS_NAME and the
# full filename will be
# SPINDLE_PUBLIC_DIRECTORY/SPINDLE_KEYWORDS_RSS_NAME .
SPINDLE_KEYWORDS_RSS_FILENAME = 'keywords.rss'

# Filename for the RSS feed of exported text, html and srt
SPINDLE_EXPORTS_RSS_FILENAME = 'exports.rss'

# Log-likelihood cutoff below which keywords will be excluded from RSS
# export
SPINDLE_KEYWORD_LL_THRESHOLD = 40

# Authentication for the Koemei speech-to-text service (koemei.com),
# accessed from Spindle via the "spindle.transcribe.koemei"
# transcription engine.
SPINDLE_KOEMEI_USERNAME = ''
SPINDLE_KOEMEI_PASSWORD = ''

# By default, Celery will use the Django database as its message
# queue. This means that all Celery processes must run on the local
# machine, and some features (like canceling/removing items from the
# queue) will be buggy.  Using RabbitMQ as the message queue is more
# robust.
BROKER_URL = 'django://'

# Uncomment the lines below to configure RabbitMQ so that
# transcription tasks can run distributed over the network.  This will
# require installing RabbitMQ and additional configuration steps.

# BROKER_URL = 'amqp://user:password@localhost/spindle'
# CELERY_RESULT_BACKEND = 'amqp'

# Use the Django-database-backed crontab scheduler, to allow
# configuring periodic tasks from the admin interface
CELERYBEAT_SCHEDULER="djcelery.schedulers.DatabaseScheduler"

#------------------------------
# Cache
#------------------------------

# Spindle stores information about running Celery tasks in the Django
# cache.  A working cache backend MUST be configured for these
# operations, including importing and exporting files, to work
# properly.
CACHES = {
    'default': {
        'BACKEND': 'django.core.cache.backends.db.DatabaseCache',
        'LOCATION': 'django_cache_table',
    }
}
